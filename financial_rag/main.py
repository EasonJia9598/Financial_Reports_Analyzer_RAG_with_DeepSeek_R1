import os
import streamlit as st
from financial_rag.backend.document_processor import DocumentProcessor
from financial_rag.backend.chatbot import Chatbot
from dotenv import load_dotenv

def main():
    # Load environment variables from .env file
    load_dotenv()

    # Get the value of EXPERT_PROMPT_FOLDER from .env (with a fallback default)
    EXPERT_PROMPT_FOLDER = os.getenv("EXPERT_PROMPT_PATH", "financial_rag/Expert_Prompt222")

    print("EXPERT_PROMPT_FOLDER: ", EXPERT_PROMPT_FOLDER)
    
    st.title("ğŸ’¬ RAG-Powered DeepSeek R1 Chatbot with Financial Expert")
    
    # åˆå§‹åŒ–ç»„ä»¶
    processor = DocumentProcessor()

    # ä¾§è¾¹æ ï¼šé€‰æ‹©ä¸“å®¶æ¨¡å‹
    with st.sidebar:
        st.subheader("ğŸ” Choose Expert Agent")
        
        # è·å– Prompt æ–‡ä»¶åˆ—è¡¨ï¼ˆå»æ‰ .txt æ‰©å±•åï¼‰
        prompt_files = [f[:-4] for f in os.listdir(EXPERT_PROMPT_FOLDER) if f.endswith(".txt")]

        # è®©ç”¨æˆ·é€‰æ‹© Promptï¼ˆä¸æ˜¾ç¤º .txtï¼‰
        selected_prompt_name = st.selectbox("Choose Agent Type", prompt_files)

        # **è¿˜åŸå®Œæ•´çš„æ–‡ä»¶å**
        selected_prompt = f"{selected_prompt_name}.txt"


        # è¯»å– Prompt æ–‡ä»¶å†…å®¹
        def load_expert_prompt(filename):
            file_path = os.path.join(EXPERT_PROMPT_FOLDER, filename)
            try:
                with open(file_path, "r", encoding="utf-8") as file:
                    return file.read().strip()
            except FileNotFoundError:
                return "Count not load the selected prompt."

        # åŠ è½½é€‰å®šçš„ Prompt
        expert_prompt = load_expert_prompt(selected_prompt)

        # åœ¨ä¾§è¾¹æ æ˜¾ç¤º Prompt é¢„è§ˆ
        # st.text_area("Prompt é¢„è§ˆ", expert_prompt, height=150)

    # **åˆå§‹åŒ– Chatbot å¹¶ä¼ é€’ä¸“å®¶ Prompt**
    chatbot = Chatbot(expert_prompt=expert_prompt)

    # åˆå§‹åŒ– session å†å²è®°å½•
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # ä¾§è¾¹æ æ–‡ä»¶ä¸Šä¼ 
    with st.sidebar:
        uploaded_file = st.file_uploader("Upload PDF for knowledge base update", type=["pdf"])

    # å¤„ç†ä¸Šä¼ çš„ PDF
    if uploaded_file:
        with st.spinner("Processing PDF..."):
            report, num_chunks = processor.process_pdf(uploaded_file)
            st.write(report)
    else:
        num_chunks = 0

    # æ˜¾ç¤ºèŠå¤©è®°å½•
    for chat in st.session_state.chat_history:
        with st.chat_message(chat["role"]):
            st.markdown(chat["content"], unsafe_allow_html=True)

    # ç”¨æˆ·è¾“å…¥
    user_input = st.chat_input("Enter your question...")

    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # **ä¼˜åŒ–**ï¼šé¿å… UI é˜»å¡
        with st.spinner("Thinking..."):
            chatbot.stream_response(user_input, num_chunks)

if __name__ == "__main__":
    main()